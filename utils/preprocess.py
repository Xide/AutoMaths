"""
Data pre-processing module.

This module is intented to preprocess raw COQ .v files into CSV ones.
"""

import os
import re
import sys
import argparse

from pygments import highlight
from pygments.lexers.theorem import CoqLexer
from pygments.formatters import RawTokenFormatter


def coq_files(folder):
    """
    Yield the file path to .v coq files.

    Files are seached in the `folder` directory
    NOTE: Those files are not open, only the filename is yielded
    """
    pass


def generate_parser():
    """Return the argv parser for pre-processing."""
    parser = argparse.ArgumentParser()
    parser.add_argument(
        'data_directory',
        help='Directory where data is downloaded'
    )
    return parser


if __name__ == '__main__':
    # Parse command line arguments
    args = generate_parser().parse_args()

    script_dir = os.path.dirname(os.path.realpath(__file__))
    data_dir = os.path.join(script_dir, args.data_directory)

    # Hardcoded input file `test.v` until the `coq_files` function is ready
    with open(os.path.join(data_dir, 'test.v'), 'r') as f:
        file_content = f.read()

    # `Pygments` lexing.
    lexed_content = highlight(file_content, CoqLexer(), RawTokenFormatter())

    # Regular expression matching a raw token line.
    regex = re.compile('Token\.((?:\w+\.?)+)\s(.*)\n?')

    # Debug, write the token stream generated by pygments into text file.
    with open('raw_results.txt', 'wb') as f:
        f.write(lexed_content)

    # Load the entire file contents into RAM as string
    # IMPROVMENT: Enhance the `RawTokenFormatter` class to stream this data
    parsed_content = str(lexed_content, encoding='utf-8')
    parsed_tab = parsed_content.splitlines()
    with open('result.txt', 'w') as f:
        is_in_proof = False

        # Iterate over every token
        for line in parsed_tab:
            match = regex.match(line)

            # If the line format does not fit with our regex, raise an error
            # and exit the application
            if match is None:
                print('Line "{}" does not fit with the regex.'.format(line))
                sys.exit(1)

            # Extract groups from the regex
            token, raw = match.group(1), match.group(2)

            # Debug: Print every proof found in the token stream
            # TODO: Split in a separated function
            if token == 'Keyword.Namespace' and 'Proof' in raw:
                is_in_proof = True
                print('>>>')
            if is_in_proof:
                print(token, raw)
            if token == 'Keyword.Namespace' and \
                    ('Qed' in raw or 'Defined' in raw):
                is_in_proof = False
                print('<<<')

            # Write the token into file for analysis
            f.write('{}\n'.format(token))
